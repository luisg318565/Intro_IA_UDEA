{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1796350",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook implementa un flujo completo para clasificaci√≥n usando XGBoost. En primer lugar, carga los datos de entrenamiento y prueba desde archivos CSV. A continuaci√≥n, realiza el preprocesamiento de los datos, que incluye limpieza, tratamiento de valores nulos y transformaci√≥n de variables si es necesario. Despu√©s construye y entrena un modelo de XGBoost (XGBClassifier) sobre los datos preprocesados. Una vez entrenado, el modelo genera predicciones sobre el conjunto de prueba y finalmente guarda estas predicciones en un archivo CSV listo para enviar como submission.\n",
    "\n",
    "Preprocesamiento: limpieza de datos (imputaci√≥n de nulos o mapeo de categor√≠as), escalado o transformaci√≥n de variables seg√∫n sea requerido.\n",
    "\n",
    "Modelo: XGBClassifier de la librer√≠a XGBoost, ajustado con hiperpar√°metros predeterminados o definidos en el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaa03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d039290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformers for encoding\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        self.freq_maps_ = {col: X[col].value_counts(normalize=True).to_dict()\n",
    "                           for col in self.columns}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, fmap in self.freq_maps_.items():\n",
    "            X[f\"{col}_FE\"] = X[col].map(fmap).fillna(0)\n",
    "        return X\n",
    "\n",
    "class CountEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        self.count_maps_ = {col: X[col].value_counts().to_dict()\n",
    "                            for col in self.columns}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, cmap in self.count_maps_.items():\n",
    "            X[f\"{col}_CE\"] = X[col].map(cmap).fillna(0)\n",
    "        return X\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. CARGA Y LIMPIEZA B√ÅSICA\n",
    "# ============================================\n",
    "# Cargar datos originales\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0ce645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=0.5, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54432ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'bajo':1, 'medio-bajo':2, 'medio-alto':3, 'alto':4}\n",
    "def clean_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    for col in df.select_dtypes(include=[np.number]):\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    binary_cols = [\n",
    "        'FAMI_TIENEINTERNET','FAMI_TIENELAVADORA','FAMI_TIENEAUTOMOVIL',\n",
    "        'FAMI_TIENECOMPUTADOR','FAMI_TIENEINTERNET.1',\n",
    "        'ESTU_PRIVADO_LIBERTAD','ESTU_PAGOMATRICULAPROPIO'\n",
    "    ]\n",
    "    for col in binary_cols:\n",
    "        if col in df:\n",
    "            df[col] = df[col].map({'Si':1, 'No':0, 'S':1, 'N':0})\n",
    "    if is_train:\n",
    "        df['RENDIMIENTO_GLOBAL_NUM'] = df['RENDIMIENTO_GLOBAL'].map(mapping)\n",
    "    return df\n",
    "\n",
    "df_train = clean_data(train, is_train=True)\n",
    "df_test  = clean_data(test,  is_train=False)\n",
    "\n",
    "# 2. Prepare features and target\n",
    "TARGET = 'RENDIMIENTO_GLOBAL_NUM'\n",
    "ID_COL = 'ID'\n",
    "X = df_train.drop([ID_COL, 'RENDIMIENTO_GLOBAL', TARGET], axis=1)\n",
    "y = df_train[TARGET]\n",
    "X_test = df_test.drop([ID_COL], axis=1)\n",
    "\n",
    "# 3. Identify categorical cardinalities\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "low_card  = [c for c in cat_cols if X[c].nunique() < 15]\n",
    "mid_card  = [c for c in cat_cols if 15 <= X[c].nunique() <= 50]\n",
    "high_card = [c for c in cat_cols if X[c].nunique() > 50]\n",
    "\n",
    "# 4. Encoding pipeline\n",
    "encoding = Pipeline([\n",
    "    ('freq',  FrequencyEncoder(mid_card)),\n",
    "    ('count', CountEncoder(high_card)),\n",
    "    ('drop',  DropColumns(mid_card + high_card))\n",
    "])\n",
    "\n",
    "# 5. Preprocessor for numeric + low-card one-hot\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), numeric_cols),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), low_card)\n",
    "], remainder='drop')\n",
    "\n",
    "# 6. Full pipeline with XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('encode', encoding),\n",
    "    ('prep',   preprocessor),\n",
    "    ('clf',    XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=4,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=1,\n",
    "        reg_lambda=1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7269f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CV Accuracy: 0.3755 ¬± 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7. Cross-validation\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y.astype(str))\n",
    "scores = cross_val_score(pipeline, X, y_enc, cv=5, scoring='accuracy')\n",
    "print(f\"‚úÖ CV Accuracy: {scores.mean():.4f} ¬± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc257212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:22:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ 'submission_xgb_tuned.csv' generated2.\n"
     ]
    }
   ],
   "source": [
    "# 8. Final training and prediction\n",
    "pipeline.fit(X, y_enc)\n",
    "preds_enc = pipeline.predict(X_test)\n",
    "preds_lbl = le.inverse_transform(preds_enc)\n",
    "\n",
    "# 9. Submission\n",
    "submission = pd.DataFrame({ID_COL: test[ID_COL], 'RENDIMIENTO_GLOBAL': preds_lbl})\n",
    "mapping = {\n",
    "        '1': 'bajo',\n",
    "        '2': 'medio-bajo',\n",
    "        '3': 'medio-alto',\n",
    "        '4': 'alto'\n",
    "    }\n",
    "\n",
    "submission['RENDIMIENTO_GLOBAL'] = submission[\"RENDIMIENTO_GLOBAL\"].map(mapping)\n",
    "submission.to_csv('submission_xgb_tuned2.csv', index=False)\n",
    "print(\"üìÑ 'submission_xgb_tuned.csv' generated2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
