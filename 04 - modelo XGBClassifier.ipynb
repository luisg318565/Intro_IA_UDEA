{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1796350",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook implementa un flujo completo para clasificación usando XGBoost. En primer lugar, carga los datos de entrenamiento y prueba desde archivos CSV. A continuación, realiza el preprocesamiento de los datos, que incluye limpieza, tratamiento de valores nulos y transformación de variables si es necesario. Después construye y entrena un modelo de XGBoost (XGBClassifier) sobre los datos preprocesados. Una vez entrenado, el modelo genera predicciones sobre el conjunto de prueba y finalmente guarda estas predicciones en un archivo CSV listo para enviar como submission.\n",
    "\n",
    "Preprocesamiento: limpieza de datos (imputación de nulos o mapeo de categorías), escalado o transformación de variables según sea requerido.\n",
    "\n",
    "Modelo: XGBClassifier de la librería XGBoost, ajustado con hiperparámetros predeterminados o definidos en el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaa03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d039290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformers for encoding\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        self.freq_maps_ = {col: X[col].value_counts(normalize=True).to_dict()\n",
    "                           for col in self.columns}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, fmap in self.freq_maps_.items():\n",
    "            X[f\"{col}_FE\"] = X[col].map(fmap).fillna(0)\n",
    "        return X\n",
    "\n",
    "class CountEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        self.count_maps_ = {col: X[col].value_counts().to_dict()\n",
    "                            for col in self.columns}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, cmap in self.count_maps_.items():\n",
    "            X[f\"{col}_CE\"] = X[col].map(cmap).fillna(0)\n",
    "        return X\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. CARGA Y LIMPIEZA BÁSICA\n",
    "# ============================================\n",
    "# Cargar datos originales\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0ce645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=0.5, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54432ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'bajo':1, 'medio-bajo':2, 'medio-alto':3, 'alto':4}\n",
    "def clean_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    for col in df.select_dtypes(include=[np.number]):\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    binary_cols = [\n",
    "        'FAMI_TIENEINTERNET','FAMI_TIENELAVADORA','FAMI_TIENEAUTOMOVIL',\n",
    "        'FAMI_TIENECOMPUTADOR','FAMI_TIENEINTERNET.1',\n",
    "        'ESTU_PRIVADO_LIBERTAD','ESTU_PAGOMATRICULAPROPIO'\n",
    "    ]\n",
    "    for col in binary_cols:\n",
    "        if col in df:\n",
    "            df[col] = df[col].map({'Si':1, 'No':0, 'S':1, 'N':0})\n",
    "    if is_train:\n",
    "        df['RENDIMIENTO_GLOBAL_NUM'] = df['RENDIMIENTO_GLOBAL'].map(mapping)\n",
    "    return df\n",
    "\n",
    "df_train = clean_data(train, is_train=True)\n",
    "df_test  = clean_data(test,  is_train=False)\n",
    "\n",
    "# 2. Prepare features and target\n",
    "TARGET = 'RENDIMIENTO_GLOBAL_NUM'\n",
    "ID_COL = 'ID'\n",
    "X = df_train.drop([ID_COL, 'RENDIMIENTO_GLOBAL', TARGET], axis=1)\n",
    "y = df_train[TARGET]\n",
    "X_test = df_test.drop([ID_COL], axis=1)\n",
    "\n",
    "# 3. Identify categorical cardinalities\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "low_card  = [c for c in cat_cols if X[c].nunique() < 15]\n",
    "mid_card  = [c for c in cat_cols if 15 <= X[c].nunique() <= 50]\n",
    "high_card = [c for c in cat_cols if X[c].nunique() > 50]\n",
    "\n",
    "# 4. Encoding pipeline\n",
    "encoding = Pipeline([\n",
    "    ('freq',  FrequencyEncoder(mid_card)),\n",
    "    ('count', CountEncoder(high_card)),\n",
    "    ('drop',  DropColumns(mid_card + high_card))\n",
    "])\n",
    "\n",
    "# 5. Preprocessor for numeric + low-card one-hot\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), numeric_cols),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), low_card)\n",
    "], remainder='drop')\n",
    "\n",
    "# 6. Full pipeline with XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('encode', encoding),\n",
    "    ('prep',   preprocessor),\n",
    "    ('clf',    XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=4,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=1,\n",
    "        reg_lambda=1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7269f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CV Accuracy: 0.3755 ± 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7. Cross-validation\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y.astype(str))\n",
    "scores = cross_val_score(pipeline, X, y_enc, cv=5, scoring='accuracy')\n",
    "print(f\"✅ CV Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc257212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:22:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Area_Trabajo\\intro_ia\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 'submission_xgb_tuned.csv' generated2.\n"
     ]
    }
   ],
   "source": [
    "# 8. Final training and prediction\n",
    "pipeline.fit(X, y_enc)\n",
    "preds_enc = pipeline.predict(X_test)\n",
    "preds_lbl = le.inverse_transform(preds_enc)\n",
    "\n",
    "# 9. Submission\n",
    "submission = pd.DataFrame({ID_COL: test[ID_COL], 'RENDIMIENTO_GLOBAL': preds_lbl})\n",
    "mapping = {\n",
    "        '1': 'bajo',\n",
    "        '2': 'medio-bajo',\n",
    "        '3': 'medio-alto',\n",
    "        '4': 'alto'\n",
    "    }\n",
    "\n",
    "submission['RENDIMIENTO_GLOBAL'] = submission[\"RENDIMIENTO_GLOBAL\"].map(mapping)\n",
    "submission.to_csv('submission_xgb_tuned2.csv', index=False)\n",
    "print(\"📄 'submission_xgb_tuned.csv' generated2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
